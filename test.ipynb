{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.3.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n      require([\"tabulator\"], function(Tabulator) {\n        window.Tabulator = Tabulator\n        on_load()\n      })\n      require([\"moment\"], function(moment) {\n        window.moment = moment\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.3/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.3/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.5.3/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.5.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.1.min.js\", \"https://cdn.holoviz.org/panel/1.5.3/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.5.3/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/css/tabulator_simple.min.css?v=1.5.3\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='bf288692-f099-4dc2-aa7b-5b32c7f5c6ae'>\n",
       "  <div id=\"e1e5329f-0317-4ca7-987d-cc08befe2e43\" data-root-id=\"bf288692-f099-4dc2-aa7b-5b32c7f5c6ae\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"17d841c6-e92b-4aa9-a827-875441cbf1e7\":{\"version\":\"3.6.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"bf288692-f099-4dc2-aa7b-5b32c7f5c6ae\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"e1309f4e-d258-4ad8-bb01-634278fc5caf\",\"attributes\":{\"plot_id\":\"bf288692-f099-4dc2-aa7b-5b32c7f5c6ae\",\"comm_id\":\"369323372fc54a139b3694c57bd14c17\",\"client_comm_id\":\"6c8901bd69594a5197c247b72f620940\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\"},{\"type\":\"model\",\"name\":\"JSComponent1\"},{\"type\":\"model\",\"name\":\"ReactComponent1\"},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\"},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"17d841c6-e92b-4aa9-a827-875441cbf1e7\",\"roots\":{\"bf288692-f099-4dc2-aa7b-5b32c7f5c6ae\":\"e1e5329f-0317-4ca7-987d-cc08befe2e43\"},\"root_ids\":[\"bf288692-f099-4dc2-aa7b-5b32c7f5c6ae\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "bf288692-f099-4dc2-aa7b-5b32c7f5c6ae"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathway as pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw.set_license_key('F0EEC7-FA3FF6-216017-196BDE-2DAC9A-V3')\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run Once\n",
    "# import nltk\n",
    "# nltk.download('punkt', download_dir='/root/nltk_data')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "os.environ[\"RUST_BACKTRACE\"] = \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/code/Pathway_RAG/env1/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Get Docs, Parser, Splitter\"\"\"\n",
    "\n",
    "folder = pw.io.fs.read(\n",
    "    path=\"./data/\",\n",
    "    format=\"binary\",\n",
    "    with_metadata=True,\n",
    ")\n",
    "\n",
    "sources = [\n",
    "    folder,\n",
    "]\n",
    "\n",
    "\n",
    "from pathway.xpacks.llm import llms, parsers, prompts\n",
    "# chat = llms.OpenAIChat(model=\"gpt-4o\")\n",
    "# table_args = {\n",
    "#    \"parsing_algorithm\": \"llm\",\n",
    "#    \"llm\": chat,\n",
    "#    \"prompt\": prompts.DEFAULT_MD_TABLE_PARSE_PROMPT,\n",
    "# }\n",
    "# image_args = {\n",
    "#     \"parsing_algorithm\": \"llm\",\n",
    "#     \"llm\": chat,\n",
    "#     \"prompt\": prompts.DEFAULT_IMAGE_PARSE_PROMPT,\n",
    "# }\n",
    "# parser = parsers.OpenParse(\n",
    "#     table_args=table_args, \n",
    "#     image_args=image_args,\n",
    "#     processing_pipeline=None # defaults to CustomIngestionPipeline() defined in _openparse_utils, we can change this by defining our own pipeline from openparse\n",
    "# )\n",
    "parser = parsers.ParseUnstructured()\n",
    "\n",
    "\n",
    "from pathway.xpacks.llm.splitters import TokenCountSplitter\n",
    "# splitter = None # OpenParse handles the text splitting\n",
    "splitter = TokenCountSplitter()\n",
    "\n",
    "\n",
    "\n",
    "from pathway.stdlib.indexing.data_index import DataIndex, InnerIndex\n",
    "from pathway.stdlib.indexing.retrievers import AbstractRetrieverFactory,InnerIndexFactory\n",
    "from pathway.stdlib.indexing.vector_document_index import default_usearch_knn_document_index\n",
    "from pathway.xpacks.llm._utils import _coerce_sync\n",
    "\n",
    "from pathway.xpacks.llm import embedders\n",
    "embedder = embedders.SentenceTransformerEmbedder(\n",
    "    model=\"intfloat/e5-large-v2\",\n",
    "    call_kwargs={}, # optional additional parameters to give to embedder\n",
    "    device=\"cpu\",\n",
    ")\n",
    "#embedder = embedders.OpenAIEmbedder(cache_strategy=DiskCache())\n",
    "\n",
    "class CustomRetrieverFactor(InnerIndexFactory):\n",
    "    def build_inner_index():\n",
    "\n",
    "        return\n",
    "    def build_index(\n",
    "        self,\n",
    "        data_column: pw.ColumnReference,\n",
    "        data_table: pw.Table,\n",
    "        metadata_column: pw.ColumnExpression | None = None,\n",
    "    ) -> DataIndex:\n",
    "        \n",
    "        self.embedder = embedder\n",
    "        self.embedding_dimension = len(_coerce_sync(self.embedder.__wrapped__)(\".\"))\n",
    "        knn_index = default_usearch_knn_document_index(\n",
    "            data_column, #chunked_docs.text,\n",
    "            data_table, #chunked_docs,\n",
    "            dimensions=self.embedding_dimension,\n",
    "            metadata_column=metadata_column, #metadata_column=chunked_docs.data[\"metadata\"],\n",
    "            embedder=self.embedder,\n",
    "        )\n",
    "        # inner_index = build_inner_index()\n",
    "        # knn_index.inner_index \n",
    "        return knn_index\n",
    "\n",
    "retriever_factory = CustomRetrieverFactor()\n",
    "\n",
    "from pathway.xpacks.llm.document_store import DocumentStore\n",
    "document_store = DocumentStore(\n",
    "    *sources,\n",
    "    retriever_factory=retriever_factory, \n",
    "    parser=parser, \n",
    "    splitter=splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" IO Test \"\"\"\n",
    "# !printf \"id,owner,pet\\\\n1,Alice,dog\\\\n2,Bob,dog\\\\n3,Alice,cat\\\\n4,Bob,dog\" > dataset.csv\n",
    "\n",
    "# import pathway as pw\n",
    "# class InputSchema(pw.Schema):\n",
    "#   owner: str\n",
    "#   pet: str\n",
    "# t = pw.io.fs.read(\"dataset.csv\", format=\"csv\", schema=InputSchema)\n",
    "# pw.debug.compute_and_print(t, include_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Make Document Store Servers \"\"\"\n",
    "\n",
    "RUST_BACKTRACE=1\n",
    "host = \"127.0.0.1\" # define server address\n",
    "port = 8667 # define server port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/code/Pathway_RAG/env1/lib/python3.12/site-packages/beartype/_util/hint/pep/utilpeptest.py:311: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.Sequence[str] deprecated by PEP 585. This hint is scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". For further commentary and alternatives, see also:\n",
      "    https://beartype.readthedocs.io/en/latest/api_roar/#pep-585-deprecations\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Thread(Thread-6 (run), started 140336489133760)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathway.xpacks.llm.servers import DocumentStoreServer\n",
    "server = DocumentStoreServer(host=host,port=port,document_store=document_store) # initialize document store server\n",
    "\n",
    "server.run(threaded=True, with_cache=True, cache_backend=pw.persistence.Backend.filesystem(\"./Cache\")) # start server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Cleaned_Parties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...</td>\n",
       "      <td>['Birch First Global Investments Inc.', 'Mount...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EuromediaHoldingsCorp_20070215_10SB12G_EX-10.B...</td>\n",
       "      <td>['Rogers Cable Communications Inc.', 'EuroMedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FulucaiProductionsLtd_20131223_10-Q_EX-10.9_83...</td>\n",
       "      <td>['CONVERGTV,\\xa0INC.', 'Fulucai Productions Lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GopageCorp_20140221_10-K_EX-10.1_8432966_EX-10...</td>\n",
       "      <td>['PSiTech Corporation', 'Empirical Ventures, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IdeanomicsInc_20160330_10-K_EX-10.26_9512211_E...</td>\n",
       "      <td>['Beijing Sun Seven Stars Culture Development ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>NEONSYSTEMSINC_03_01_1999-EX-10.5-DISTRIBUTOR ...</td>\n",
       "      <td>['Peregrine/Bridge Transfer Corporation', 'Neo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>WOMENSGOLFUNLIMITEDINC_03_29_2000-EX-10.13-END...</td>\n",
       "      <td>['SQUARE TWO GOLF INC.', 'KATHY WHITWORTH']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>WOMENSGOLFUNLIMITEDINC_03_29_2000-EX-10.13-END...</td>\n",
       "      <td>['SQUARE TWO GOLF INC.', 'KATHY WHITWORTH']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>KUBIENT,INC_07_02_2020-EX-10.14-MASTER SERVICE...</td>\n",
       "      <td>['Kubient, Inc.', 'The Associated Press']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>KUBIENT,INC_07_02_2020-EX-10.14-MASTER SERVICE...</td>\n",
       "      <td>['Kubient Inc.', 'The Associated Press']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Filename  \\\n",
       "0    CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605...   \n",
       "1    EuromediaHoldingsCorp_20070215_10SB12G_EX-10.B...   \n",
       "2    FulucaiProductionsLtd_20131223_10-Q_EX-10.9_83...   \n",
       "3    GopageCorp_20140221_10-K_EX-10.1_8432966_EX-10...   \n",
       "4    IdeanomicsInc_20160330_10-K_EX-10.26_9512211_E...   \n",
       "..                                                 ...   \n",
       "505  NEONSYSTEMSINC_03_01_1999-EX-10.5-DISTRIBUTOR ...   \n",
       "506  WOMENSGOLFUNLIMITEDINC_03_29_2000-EX-10.13-END...   \n",
       "507  WOMENSGOLFUNLIMITEDINC_03_29_2000-EX-10.13-END...   \n",
       "508  KUBIENT,INC_07_02_2020-EX-10.14-MASTER SERVICE...   \n",
       "509  KUBIENT,INC_07_02_2020-EX-10.14-MASTER SERVICE...   \n",
       "\n",
       "                                       Cleaned_Parties  \n",
       "0    ['Birch First Global Investments Inc.', 'Mount...  \n",
       "1    ['Rogers Cable Communications Inc.', 'EuroMedi...  \n",
       "2    ['CONVERGTV,\\xa0INC.', 'Fulucai Productions Lt...  \n",
       "3    ['PSiTech Corporation', 'Empirical Ventures, I...  \n",
       "4    ['Beijing Sun Seven Stars Culture Development ...  \n",
       "..                                                 ...  \n",
       "505  ['Peregrine/Bridge Transfer Corporation', 'Neo...  \n",
       "506        ['SQUARE TWO GOLF INC.', 'KATHY WHITWORTH']  \n",
       "507        ['SQUARE TWO GOLF INC.', 'KATHY WHITWORTH']  \n",
       "508          ['Kubient, Inc.', 'The Associated Press']  \n",
       "509           ['Kubient Inc.', 'The Associated Press']  \n",
       "\n",
       "[510 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('metadata_filename_parties.csv')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(metadata['Filename'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_companies_from_question(question):\n",
    "    pattern = r'between\\s+(.+?)\\s+and\\s+(.+?)\\?'\n",
    "    \n",
    "    match = re.search(pattern, question)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the two companies\n",
    "        company_1 = match.group(1).strip()\n",
    "        company_2 = match.group(2).strip()\n",
    "        return [company_1, company_2]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two companies are: ['Birch First Global Investments Inc.', 'Mount Kowledge Holdings Inc.']\n",
      "birch first global investments inc. mount kowledge holdings inc.\n",
      "['CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605784_EX-10.27_Affiliate Agreement', '']\n",
      "CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605784_EX-10.27_Affiliate Agreement.txt\n",
      "The contract filename is: CybergyHoldingsInc_20140520_10-Q_EX-10.27_8605784_EX-10.27_Affiliate Agreement.txt\n"
     ]
    }
   ],
   "source": [
    "def find_contract_filename(companies, company_contract_df):\n",
    "    if len(companies) != 2:\n",
    "        return \"Error: Two companies are needed.\"\n",
    "\n",
    "    # Normalize company names for case-insensitive matching (strip spaces and lower case)\n",
    "    company1, company2 = [company.strip().lower() for company in companies]\n",
    "    print(company1, company2)\n",
    "\n",
    "    # Loop through each contract to check if the companies are involved\n",
    "    for _, row in company_contract_df.iterrows():\n",
    "        # Clean and normalize the party list in the row\n",
    "        cleaned_parties = eval(row['Cleaned_Parties'])  # Convert string list to actual list\n",
    "        cleaned_parties = [party.strip().lower() for party in cleaned_parties]\n",
    "\n",
    "        # Check if both companies are in the list of parties\n",
    "        if company1 in cleaned_parties and company2 in cleaned_parties:\n",
    "            return row['Filename']  # Return the corresponding contract filename\n",
    "    \n",
    "    return \"No contract found between the given companies.\"\n",
    "\n",
    "# Example CSV file path\n",
    "csv_file_path = 'metadata_filename_parties.csv'\n",
    "company_contract_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "query = \"What is the Agreement Date for the contract between Birch First Global Investments Inc. and Mount Kowledge Holdings Inc.?\"\n",
    "\n",
    "companies = extract_companies_from_question(query)\n",
    "if companies:\n",
    "    print(f\"The two companies are: {companies}\")\n",
    "    contract_filename = find_contract_filename(companies, company_contract_df)\n",
    "    print(contract_filename.split(\".pdf\"))\n",
    "    l = contract_filename.split(\".pdf\")\n",
    "    l.append('.txt')\n",
    "    contract_filename = ''.join(l)\n",
    "    print(''.join(l))\n",
    "    print(f\"The contract filename is: {contract_filename}\")\n",
    "else:\n",
    "    print(\"No companies found in the query.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Birch First Global Investments Inc.', 'Mount Kowledge Holdings Inc.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = extract_companies_from_question(query)\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Make DocumentStoreClient \"\"\"\n",
    "import json\n",
    "import requests\n",
    "\n",
    "class DocumentStoreClient:\n",
    "    \"\"\"\n",
    "    A client you can use to query DocumentStoreServer.\n",
    "\n",
    "    Please provide either the `url`, or `host` and `port`.\n",
    "\n",
    "    Args:\n",
    "        host: host on which `DocumentStoreServer </developers/api-docs/pathway-xpacks-llm/documentstore#pathway.xpacks.llm.document_store.DocumentStoreServer>`_ listens\n",
    "        port: port on which `DocumentStoreServer </developers/api-docs/pathway-xpacks-llm/documentstore#pathway.xpacks.llm.document_store.DocumentStoreServer>`_ listens\n",
    "        url: url at which `DocumentStoreServer </developers/api-docs/pathway-xpacks-llm/documentstore#pathway.xpacks.llm.document_store.DocumentStoreServer>`_ listens\n",
    "        timeout: timeout for the post requests in seconds\n",
    "    \"\"\"  # noqa\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        host: str | None = None,\n",
    "        port: int | None = None,\n",
    "        url: str | None = None,\n",
    "        timeout: int | None = 300,\n",
    "        additional_headers: dict | None = None,\n",
    "    ):\n",
    "        err = \"Either (`host` and `port`) or `url` must be provided, but not both.\"\n",
    "        if url is not None:\n",
    "            if host or port:\n",
    "                raise ValueError(err)\n",
    "            self.url = url\n",
    "        else:\n",
    "            if host is None:\n",
    "                raise ValueError(err)\n",
    "            port = port or 80\n",
    "            self.url = f\"http://{host}:{port}\"\n",
    "\n",
    "        self.timeout = timeout\n",
    "        self.additional_headers = additional_headers or {}\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        query: str,\n",
    "        k: int = 3,\n",
    "        metadata_filter: str | None = None,\n",
    "        filepath_globpattern: str | None = None,\n",
    "    ) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Perform a query to the vector store and fetch results.\n",
    "\n",
    "        Args:\n",
    "            query:\n",
    "            k: number of documents to be returned\n",
    "            metadata_filter: optional string representing the metadata filtering query\n",
    "                in the JMESPath format. The search will happen only for documents\n",
    "                satisfying this filtering.\n",
    "            filepath_globpattern: optional glob pattern specifying which documents\n",
    "                will be searched for this query.\n",
    "        \"\"\"\n",
    "\n",
    "        data = {\"query\": query, \"k\": k}\n",
    "        print(\"lol\")\n",
    "        print(data)\n",
    "\n",
    "        query = data['query']\n",
    "        print(query)\n",
    "        # companies = extract_companies_from_question(query)\n",
    "        companies = True\n",
    "        # print(companies)\n",
    "\n",
    "        if companies:\n",
    "            # metadata_filter = find_contract_filename(companies, company_contract_df)\n",
    "            # metadata_filter = metadata_filter.split(\".pdf\")[0].replace('-', '_').replace('.', '_').replace(' ','_')\n",
    "            # print(metadata_filter)\n",
    "            \n",
    "            if metadata_filter is not None:\n",
    "                data[\"metadata_filter\"] = metadata_filter#f\"\"\"contains(path, '{metadata_filter}')\"\"\"\n",
    "            if filepath_globpattern is not None:\n",
    "                data[\"filepath_globpattern\"] = filepath_globpattern\n",
    "            url = self.url + \"/v1/retrieve\"\n",
    "            print(data)\n",
    "            response = requests.post(\n",
    "                url,\n",
    "                data=json.dumps(data),\n",
    "                headers=self._get_request_headers(),\n",
    "                timeout=self.timeout,\n",
    "            )\n",
    "\n",
    "            responses = response.json()\n",
    "            return sorted(responses, key=lambda x: x[\"dist\"])\n",
    "        \n",
    "        else:\n",
    "            print(\"Weren't able to trace company\")\n",
    "\n",
    "    # Make an alias\n",
    "    __call__ = query\n",
    "\n",
    "    def _get_request_headers(self):\n",
    "        request_headers = {\"Content-Type\": \"application/json\"}\n",
    "        request_headers.update(self.additional_headers)\n",
    "        return request_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "{'query': 'What is the Agreement Date for the contract between Birch First Global Investments Inc. and Mount Kowledge Holdings Inc.?', 'k': 3}\n",
      "What is the Agreement Date for the contract between Birch First Global Investments Inc. and Mount Kowledge Holdings Inc.?\n",
      "{'query': 'What is the Agreement Date for the contract between Birch First Global Investments Inc. and Mount Kowledge Holdings Inc.?', 'k': 3, 'filepath_globpattern': '**/CybergyHoldingsInc_20140520_10_Q_EX_10_27_8605784_EX_10_27_Affiliate_Agreement.txt'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Showcasing Retriver Functionality \"\"\"\n",
    "client = DocumentStoreClient(\n",
    "    host=host,\n",
    "    port=port,\n",
    ")\n",
    "\n",
    "queryy = \"What is the Agreement Date for the contract between Birch First Global Investments Inc. and Mount Kowledge Holdings Inc.?\"\n",
    "results = client.query(queryy, filepath_globpattern=\"**/CybergyHoldingsInc_20140520_10_Q_EX_10_27_8605784_EX_10_27_Affiliate_Agreement.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = []\n",
    "for result in results:\n",
    "    context.append(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# retriever = client.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "You are smart assistant that helps users with their documents on Google Drive and Sharepoint.\n",
    "Given a context, respond to the user question.\n",
    "CONTEXT:\n",
    "{context}\n",
    "QUESTION: {question}\n",
    "YOUR ANSWER:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "# llm = ChatOpenAI()\n",
    "model = ChatGroq(temperature=0, model_name=\"llama3-70b-8192\")\n",
    "chain_summarize = prompt | model\n",
    "response = chain_summarize.invoke({\"context\" : context, \"question\" : queryy})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"What is Pathway?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.get_vectorstore_statistics())\n",
    "print(client.get_input_files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('contract_questions_and_answers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df['Question'].tolist()\n",
    "inference_results = []\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Querying: {query}\")\n",
    "    response = client.query(query, k=3)  \n",
    "    inference_results.append({\n",
    "        \"query\": query,\n",
    "        \"response\": response  \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(predicted, actual):\n",
    "    try:\n",
    "        predicted_num = float(predicted)\n",
    "        actual_num = float(actual)\n",
    "        absolute_diff = abs(predicted_num - actual_num)\n",
    "        relative_diff = abs((predicted_num - actual_num) / actual_num) * 100 if actual_num != 0 else float('inf')\n",
    "        return {\n",
    "            'type': 'numeric',\n",
    "            'absolute_diff': absolute_diff,\n",
    "            'relative_diff_percentage': relative_diff\n",
    "        }\n",
    "    except ValueError:\n",
    "        predicted_str = str(predicted).strip().lower()\n",
    "        actual_str = str(actual).strip().lower()\n",
    "        exact_match = predicted_str == actual_str\n",
    "        similarity = SequenceMatcher(None, predicted_str, actual_str).ratio() * 100  \n",
    "        \n",
    "        return {\n",
    "            'type': 'string',\n",
    "            'exact_match': exact_match,\n",
    "            'similarity_percentage': similarity\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"response\"] = inference_results\n",
    "\n",
    "eval_results = []\n",
    "for index, row in df.iterrows():\n",
    "    predicted = row['response'] \n",
    "    actual = row['Answer']  \n",
    "    evaluation = evaluate_answer(predicted, actual)\n",
    "    eval_results.append(evaluation)\n",
    "\n",
    "df['eval'] = eval_results\n",
    "df.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
